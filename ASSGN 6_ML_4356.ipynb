{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8c245b-228a-439a-854e-b6a302477702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ann_visualizer\n",
      "  Downloading ann_visualizer-2.5.tar.gz (4.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ann_visualizer\n",
      "  Building wheel for ann_visualizer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ann_visualizer: filename=ann_visualizer-2.5-py3-none-any.whl size=4167 sha256=73ba3eb6e536da76a5e4128571b42866715fc34909de55a3f7d220ef0b1ffa99\n",
      "  Stored in directory: /Users/vanshvatsal/Library/Caches/pip/wheels/28/4a/ad/e82da1aad2994e42bf0f4b1d403fdd8a64dfc38ae2c8a5daa4\n",
      "Successfully built ann_visualizer\n",
      "Installing collected packages: ann_visualizer\n",
      "Successfully installed ann_visualizer-2.5\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ann_visualizer\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f945622-fa6d-4f3b-94a2-4b692b67c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x105dcb6d0>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/keras/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting keras\n",
      "  Downloading keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "Successfully installed keras-2.14.0\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b88b941-772c-4387-b1df-1d658f274d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-macos==2.14.0 (from tensorflow)\n",
      "  Downloading tensorflow_macos-2.14.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.25.2)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading wrapt-1.14.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading grpcio-1.59.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.41.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading Markdown-3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2023.7.22)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.14.0-cp311-cp311-macosx_12_0_arm64.whl (2.1 kB)\n",
      "Downloading tensorflow_macos-2.14.0-cp311-cp311-macosx_12_0_arm64.whl (199.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.59.0-cp311-cp311-macosx_10_10_universal2.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-16.0.6-py2.py3-none-macosx_11_0_arm64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.24.4-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.4/409.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp311-cp311-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Downloading wrapt-1.14.1-cp311-cp311-macosx_11_0_arm64.whl (36 kB)\n",
      "Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading charset_normalizer-3.3.1-cp311-cp311-macosx_11_0_arm64.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.8/116.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_universal2.whl (17 kB)\n",
      "Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, MarkupSafe, markdown, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, cachetools, astunparse, absl-py, werkzeug, rsa, requests, pyasn1-modules, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-macos, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.3 absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 charset-normalizer-3.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.10.0 idna-3.4 libclang-16.0.6 markdown-3.5 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-macos-2.14.0 termcolor-2.3.0 typing-extensions-4.8.0 urllib3-2.0.7 werkzeug-3.0.1 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c2175b6-cbe2-40ea-9c77-b99965ba9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "import keras\n",
    "# Import the necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90de72e8-6d34-486b-8ab2-9f2390c80ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e31f23a-6b60-401b-8bab-7ffd702ad660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pima-indians-diabetes.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450a087e-5b55-46ba-913c-fc6f21479ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e264d8b0-202f-4550-83b3-a0c8654422b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['6', '148', '72', '35', '0', '33.6', '0.627', '50', '1'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c5cb76-3db8-4abd-a3ce-5cc51f32ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b9054b-f6c7-476f-a44a-cbbb1ebd2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fc54a25-38ec-4799-9e9a-7fb97aa6755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "77/77 [==============================] - 0s 653us/step - loss: 1.9202 - accuracy: 0.4550\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 584us/step - loss: 0.7623 - accuracy: 0.5750\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 580us/step - loss: 0.7572 - accuracy: 0.5515\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.7086 - accuracy: 0.5671\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 556us/step - loss: 0.6981 - accuracy: 0.5828\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 558us/step - loss: 0.6856 - accuracy: 0.6115\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 577us/step - loss: 0.6728 - accuracy: 0.6128\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.6631 - accuracy: 0.6232\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 961us/step - loss: 0.6674 - accuracy: 0.6167\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.6454 - accuracy: 0.6571\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.6472 - accuracy: 0.6532\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 612us/step - loss: 0.6480 - accuracy: 0.6584\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.6515 - accuracy: 0.6428\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 590us/step - loss: 0.6271 - accuracy: 0.6832\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 601us/step - loss: 0.6231 - accuracy: 0.6806\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 581us/step - loss: 0.6291 - accuracy: 0.6701\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.6245 - accuracy: 0.6675\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 577us/step - loss: 0.6222 - accuracy: 0.6558\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.6264 - accuracy: 0.6636\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 563us/step - loss: 0.6051 - accuracy: 0.6767\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 558us/step - loss: 0.6053 - accuracy: 0.6662\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 562us/step - loss: 0.5949 - accuracy: 0.6780\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.5920 - accuracy: 0.6871\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 554us/step - loss: 0.5982 - accuracy: 0.6936\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 560us/step - loss: 0.5888 - accuracy: 0.6858\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 589us/step - loss: 0.5872 - accuracy: 0.7027\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 567us/step - loss: 0.5886 - accuracy: 0.6936\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 575us/step - loss: 0.5933 - accuracy: 0.6819\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 577us/step - loss: 0.5909 - accuracy: 0.6923\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 605us/step - loss: 0.5739 - accuracy: 0.7132\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 573us/step - loss: 0.5705 - accuracy: 0.7040\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 561us/step - loss: 0.5830 - accuracy: 0.6988\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.5573 - accuracy: 0.7210\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.5571 - accuracy: 0.7158\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.5645 - accuracy: 0.7053\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 558us/step - loss: 0.5600 - accuracy: 0.7171\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 582us/step - loss: 0.5556 - accuracy: 0.7132\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 583us/step - loss: 0.5560 - accuracy: 0.7184\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 567us/step - loss: 0.5657 - accuracy: 0.7145\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 562us/step - loss: 0.5726 - accuracy: 0.7027\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.5495 - accuracy: 0.7327\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 582us/step - loss: 0.5514 - accuracy: 0.7249\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.5402 - accuracy: 0.7262\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 569us/step - loss: 0.5454 - accuracy: 0.7236\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 581us/step - loss: 0.5318 - accuracy: 0.7445\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 591us/step - loss: 0.5391 - accuracy: 0.7249\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.5350 - accuracy: 0.7314\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.5374 - accuracy: 0.7314\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.5358 - accuracy: 0.7379\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 594us/step - loss: 0.5423 - accuracy: 0.7288\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 914us/step - loss: 0.5213 - accuracy: 0.7445\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 582us/step - loss: 0.5255 - accuracy: 0.7419\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.5226 - accuracy: 0.7314\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 595us/step - loss: 0.5286 - accuracy: 0.7445\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 618us/step - loss: 0.5266 - accuracy: 0.7366\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.5349 - accuracy: 0.7379\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 589us/step - loss: 0.5202 - accuracy: 0.7484\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 595us/step - loss: 0.5266 - accuracy: 0.7458\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 575us/step - loss: 0.5262 - accuracy: 0.7340\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 562us/step - loss: 0.5410 - accuracy: 0.7275\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.5145 - accuracy: 0.7405\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 561us/step - loss: 0.5194 - accuracy: 0.7575\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 558us/step - loss: 0.5157 - accuracy: 0.7484\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 562us/step - loss: 0.5139 - accuracy: 0.7484\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 561us/step - loss: 0.5247 - accuracy: 0.7327\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 552us/step - loss: 0.5167 - accuracy: 0.7484\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 552us/step - loss: 0.5158 - accuracy: 0.7536\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 556us/step - loss: 0.5066 - accuracy: 0.7601\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 560us/step - loss: 0.5087 - accuracy: 0.7432\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 561us/step - loss: 0.5108 - accuracy: 0.7497\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.5112 - accuracy: 0.7353\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 585us/step - loss: 0.5102 - accuracy: 0.7523\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.5071 - accuracy: 0.7484\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.5083 - accuracy: 0.7405\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 557us/step - loss: 0.5114 - accuracy: 0.7471\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 582us/step - loss: 0.5130 - accuracy: 0.7614\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 592us/step - loss: 0.5180 - accuracy: 0.7419\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 574us/step - loss: 0.5103 - accuracy: 0.7497\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.5038 - accuracy: 0.7810\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 612us/step - loss: 0.5011 - accuracy: 0.7510\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 0s 593us/step - loss: 0.5065 - accuracy: 0.7614\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 0s 906us/step - loss: 0.4980 - accuracy: 0.7523\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 581us/step - loss: 0.5264 - accuracy: 0.7497\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4964 - accuracy: 0.7497\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5022 - accuracy: 0.7536\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.5216 - accuracy: 0.7432\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.5051 - accuracy: 0.7510\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.4948 - accuracy: 0.7484\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4974 - accuracy: 0.7679\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4980 - accuracy: 0.7549\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4958 - accuracy: 0.7653\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 567us/step - loss: 0.4921 - accuracy: 0.7562\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 565us/step - loss: 0.4995 - accuracy: 0.7562\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4951 - accuracy: 0.7575\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 599us/step - loss: 0.4944 - accuracy: 0.7523\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4923 - accuracy: 0.7640\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.4858 - accuracy: 0.7588\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 580us/step - loss: 0.4910 - accuracy: 0.7562\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 580us/step - loss: 0.4856 - accuracy: 0.7614\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4913 - accuracy: 0.7627\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4827 - accuracy: 0.7640\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4848 - accuracy: 0.7705\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4920 - accuracy: 0.7614\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 569us/step - loss: 0.4833 - accuracy: 0.7679\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 563us/step - loss: 0.4855 - accuracy: 0.7588\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.5029 - accuracy: 0.7705\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 577us/step - loss: 0.4854 - accuracy: 0.7640\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 564us/step - loss: 0.4826 - accuracy: 0.7692\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 569us/step - loss: 0.4796 - accuracy: 0.7588\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.4905 - accuracy: 0.7614\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 587us/step - loss: 0.4826 - accuracy: 0.7601\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4937 - accuracy: 0.7614\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 562us/step - loss: 0.4743 - accuracy: 0.7731\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 560us/step - loss: 0.4888 - accuracy: 0.7705\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 560us/step - loss: 0.4849 - accuracy: 0.7549\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 556us/step - loss: 0.4821 - accuracy: 0.7731\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4766 - accuracy: 0.7771\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.4913 - accuracy: 0.7692\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 562us/step - loss: 0.4810 - accuracy: 0.7771\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.4773 - accuracy: 0.7731\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4771 - accuracy: 0.7705\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 585us/step - loss: 0.4783 - accuracy: 0.7653\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4820 - accuracy: 0.7679\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4792 - accuracy: 0.7757\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.4743 - accuracy: 0.7640\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.4743 - accuracy: 0.7692\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 862us/step - loss: 0.4766 - accuracy: 0.7679\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 583us/step - loss: 0.4887 - accuracy: 0.7679\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 569us/step - loss: 0.4733 - accuracy: 0.7692\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4695 - accuracy: 0.7692\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4696 - accuracy: 0.7757\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4817 - accuracy: 0.7666\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4811 - accuracy: 0.7731\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 569us/step - loss: 0.4768 - accuracy: 0.7666\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 612us/step - loss: 0.4711 - accuracy: 0.7757\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 580us/step - loss: 0.4682 - accuracy: 0.7705\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4720 - accuracy: 0.7666\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4635 - accuracy: 0.7810\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4698 - accuracy: 0.7744\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.4683 - accuracy: 0.7797\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 593us/step - loss: 0.4675 - accuracy: 0.7836\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 575us/step - loss: 0.4666 - accuracy: 0.7875\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4709 - accuracy: 0.7731\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4679 - accuracy: 0.7731\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 585us/step - loss: 0.4815 - accuracy: 0.7784\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4725 - accuracy: 0.7823\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4687 - accuracy: 0.7810\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4605 - accuracy: 0.7771\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 577us/step - loss: 0.4641 - accuracy: 0.7810\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4822 - accuracy: 0.7653\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.4745 - accuracy: 0.7731\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 568us/step - loss: 0.4637 - accuracy: 0.7810\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 573us/step - loss: 0.4645 - accuracy: 0.7823\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 567us/step - loss: 0.4835 - accuracy: 0.7836\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 599us/step - loss: 0.4602 - accuracy: 0.7862\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 619us/step - loss: 0.4599 - accuracy: 0.7771\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 658us/step - loss: 0.4632 - accuracy: 0.7784\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 627us/step - loss: 0.4591 - accuracy: 0.7823\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4618 - accuracy: 0.7810\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4712 - accuracy: 0.7757\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 0s 581us/step - loss: 0.4627 - accuracy: 0.7705\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 934us/step - loss: 0.4625 - accuracy: 0.7692\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4628 - accuracy: 0.7823\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4704 - accuracy: 0.7731\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4570 - accuracy: 0.7784\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 585us/step - loss: 0.4581 - accuracy: 0.7914\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4507 - accuracy: 0.7849\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 580us/step - loss: 0.4647 - accuracy: 0.7810\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 583us/step - loss: 0.4535 - accuracy: 0.7757\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 574us/step - loss: 0.4645 - accuracy: 0.7953\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 577us/step - loss: 0.4768 - accuracy: 0.7823\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 579us/step - loss: 0.4531 - accuracy: 0.7940\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 583us/step - loss: 0.4582 - accuracy: 0.7875\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4617 - accuracy: 0.7901\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 566us/step - loss: 0.4505 - accuracy: 0.7901\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.4699 - accuracy: 0.7692\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 580us/step - loss: 0.4578 - accuracy: 0.7823\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 581us/step - loss: 0.4547 - accuracy: 0.7744\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 559us/step - loss: 0.4519 - accuracy: 0.7875\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 600us/step - loss: 0.4487 - accuracy: 0.7940\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 574us/step - loss: 0.4529 - accuracy: 0.7862\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4512 - accuracy: 0.7901\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 575us/step - loss: 0.4463 - accuracy: 0.7901\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4518 - accuracy: 0.7810\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 586us/step - loss: 0.4525 - accuracy: 0.7836\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 576us/step - loss: 0.4544 - accuracy: 0.7914\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 570us/step - loss: 0.4543 - accuracy: 0.7862\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 571us/step - loss: 0.4582 - accuracy: 0.7718\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 575us/step - loss: 0.4472 - accuracy: 0.7823\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 578us/step - loss: 0.4658 - accuracy: 0.7705\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 572us/step - loss: 0.4591 - accuracy: 0.7862\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.4513 - accuracy: 0.7836\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 659us/step - loss: 0.4632 - accuracy: 0.7666\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 664us/step - loss: 0.4527 - accuracy: 0.7849\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 652us/step - loss: 0.4478 - accuracy: 0.7836\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 684us/step - loss: 0.4444 - accuracy: 0.7797\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 753us/step - loss: 0.4436 - accuracy: 0.7992\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 690us/step - loss: 0.4456 - accuracy: 0.7901\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 658us/step - loss: 0.4512 - accuracy: 0.7849\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 660us/step - loss: 0.4536 - accuracy: 0.7862\n",
      "24/24 [==============================] - 0s 677us/step - loss: 0.4403 - accuracy: 0.7901\n",
      "Accuracy: 79.01\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.layers' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mann_visualizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ann_viz;\n\u001b[0;32m---> 13\u001b[0m \u001b[43mann_viz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mArtificial Neural Network\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ann_visualizer/visualize.py:44\u001b[0m, in \u001b[0;36mann_viz\u001b[0;34m(model, view, filename, title)\u001b[0m\n\u001b[1;32m     42\u001b[0m input_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(layer\u001b[38;5;241m.\u001b[39minput_shape)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]);\n\u001b[1;32m     43\u001b[0m hidden_layers_nr \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m;\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(layer) \u001b[38;5;241m==\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mDense):\n\u001b[1;32m     45\u001b[0m     hidden_layers\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(layer\u001b[38;5;241m.\u001b[39moutput_shape)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]));\n\u001b[1;32m     46\u001b[0m     layer_types\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDense\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.layers' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fitting of model\n",
    "model.fit(X, y, epochs=200, batch_size=10)\n",
    "# evaluation\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model, title=\"Artificial Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e69159-d437-475c-a090-91dc4054327a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
